{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Image Super-Resolution with ESPCN\n",
    "For a full explanation of the concepts included in this notebook, check out [Image Super-Resolution: A Comprehensive Review](https://blog.paperspace.com/image-super-resolution/) on the blog. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "We will be using the DIV2K dataset to train the model. We split the 2k resolution images into patches of 17Ã—17 to provide as model input for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "me57uIsYdv3-"
   },
   "outputs": [],
   "source": [
    "!wget data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
    "!unzip DIV2K_train_HR.zip -d ./Training\n",
    "!rm DIV2K_train_HR.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update && apt install -y libsm6 libxext6 libxrender-dev\n",
    "!apt install -y libgl1-mesa-glx\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "sVXXCtMszBpe"
   },
   "outputs": [],
   "source": [
    "upscale_factor = 3\n",
    "\n",
    "inputs = keras.Input(shape=(None, None, 1))\n",
    "conv1 = layers.Conv2D(64, 5, activation=\"tanh\", padding=\"same\")(inputs)\n",
    "conv2 = layers.Conv2D(32, 3, activation=\"tanh\", padding=\"same\")(conv1)\n",
    "conv3 = layers.Conv2D((upscale_factor*upscale_factor), 3, activation=\"sigmoid\", padding=\"same\")(conv2)\n",
    "outputs = tf.nn.depth_to_space(conv3, upscale_factor, data_format='NHWC')\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "QvIz7T9M6RDm"
   },
   "outputs": [],
   "source": [
    "def gen_dataset(filenames, scale):\n",
    "    # The model trains on 17x17 patches\n",
    "    crop_size_lr = 17\n",
    "    crop_size_hr = 17 * scale\n",
    "\n",
    "    for p in filenames:\n",
    "        image_decoded = cv2.imread(\"Training/DIV2K_train_HR/\"+p.decode(), 3).astype(np.float32) / 255.0\n",
    "        imgYCC = cv2.cvtColor(image_decoded, cv2.COLOR_BGR2YCrCb)\n",
    "        cropped = imgYCC[0:(imgYCC.shape[0] - (imgYCC.shape[0] % scale)),\n",
    "                  0:(imgYCC.shape[1] - (imgYCC.shape[1] % scale)), :]\n",
    "        lr = cv2.resize(cropped, (int(cropped.shape[1] / scale), int(cropped.shape[0] / scale)),\n",
    "                        interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        hr_y = imgYCC[:, :, 0]\n",
    "        lr_y = lr[:, :, 0]\n",
    "\n",
    "        numx = int(lr.shape[0] / crop_size_lr)\n",
    "        numy = int(lr.shape[1] / crop_size_lr)\n",
    "        for i in range(0, numx):\n",
    "            startx = i * crop_size_lr\n",
    "            endx = (i * crop_size_lr) + crop_size_lr\n",
    "            startx_hr = i * crop_size_hr\n",
    "            endx_hr = (i * crop_size_hr) + crop_size_hr\n",
    "            for j in range(0, numy):\n",
    "                starty = j * crop_size_lr\n",
    "                endy = (j * crop_size_lr) + crop_size_lr\n",
    "                starty_hr = j * crop_size_hr\n",
    "                endy_hr = (j * crop_size_hr) + crop_size_hr\n",
    "\n",
    "                crop_lr = lr_y[startx:endx, starty:endy]\n",
    "                crop_hr = hr_y[startx_hr:endx_hr, starty_hr:endy_hr]\n",
    "\n",
    "                hr = crop_hr.reshape((crop_size_hr, crop_size_hr, 1))\n",
    "                lr = crop_lr.reshape((crop_size_lr, crop_size_lr, 1))\n",
    "                yield lr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "blzlC2gt6UTF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "filenames = os.listdir(\"Training/DIV2K_train_HR/\")\n",
    "ds = tf.data.Dataset.from_generator(\n",
    "        gen_dataset, (tf.float32, tf.float32), (tf.TensorShape([None, None, 1]), tf.TensorShape([None, None, 1])),\n",
    "        args=[filenames, upscale_factor]).batch(64).shuffle(buffer_size=10000)\n",
    "\n",
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=max_pixel)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='mse', \n",
    "              metrics=[PSNR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "lnQcykwJ9HhE"
   },
   "outputs": [],
   "source": [
    "model.fit(ds, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "Peak Signal to Noise Ratio is the most common technique used to determine the quality of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def PSNR(orig, reconstr):\n",
    "    mse = np.mean((orig.astype(float) - reconstr.astype(float)) ** 2)\n",
    "    if mse != 0:\n",
    "        max_pixel = 255.0\n",
    "        return 20 * math.log10(max_pixel / math.sqrt(mse))\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The authors convert RGB images to the YCrCb format, and then upscale the Y channel input using ESPCN. The Cr and Cb channels are upscaled using bicubic interpolation, and all the upscaled channels are stitched together to get the final HR image. Thus, while training, we only need to provide the Y channel of the low resolution data and the high resolution images to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image\n",
    "!wget https://s3.amazonaws.com/ps.public.resources/ml-showcase/messi.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "gradient": {},
    "id": "Cvb_t7gpK5oV",
    "outputId": "8e1ade87-ace3-4ed5-d0f2-422dfcb5e13e"
   },
   "outputs": [],
   "source": [
    "fullimg = cv2.imread(\"messi.jpg\", 3)\n",
    "width = fullimg.shape[0]\n",
    "height = fullimg.shape[1]\n",
    "cropped = fullimg[0:(width - (width % upscale_factor)), 0:(height - (height % upscale_factor)), :]\n",
    "img = cv2.resize(cropped, None, fx=1. / upscale_factor, fy=1. / upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "floatimg = img.astype(np.float32) / 255.0\n",
    "imgYCbCr = cv2.cvtColor(floatimg, cv2.COLOR_BGR2YCrCb)\n",
    "imgY = imgYCbCr[:, :, 0]\n",
    "LR_input_ = imgY.reshape(1, imgY.shape[0], imgY.shape[1], 1)\n",
    "Y = model.predict([LR_input_])[0]\n",
    "Cr = np.expand_dims(cv2.resize(imgYCbCr[:, :, 1], None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC),\n",
    "                    axis=2)\n",
    "Cb = np.expand_dims(cv2.resize(imgYCbCr[:, :, 2], None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC),\n",
    "                    axis=2)\n",
    "HR_image_YCrCb = np.concatenate((Y, Cr, Cb), axis=2)\n",
    "HR_image = ((cv2.cvtColor(HR_image_YCrCb, cv2.COLOR_YCrCb2BGR)) * 255.0).clip(min=0, max=255)\n",
    "HR_image = (HR_image).astype(np.uint8)\n",
    "bicubic_image = cv2.resize(img, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "print(\"PSNR of ESPCN generated image: \", PSNR(cropped, HR_image))\n",
    "print(\"PSNR of bicubic interpolated image: \", PSNR(cropped, bicubic_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "gradient": {},
    "id": "o5R0gSROMFY-",
    "outputId": "efb2e760-6498-4b1c-e6f8-a1dfd2a56df8"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(cv2.cvtColor(HR_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "gradient": {},
    "id": "zLGE03TZMJCY",
    "outputId": "ed27051d-f7cb-47b4-8788-e37c875a0f08"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(bicubic_image, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ESPCN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
